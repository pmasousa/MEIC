{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyZx55TWTbyg"
      },
      "source": [
        "# Testing NLP libraries: NLTK and SpaCy (part-of-speech tagging)\n",
        "\n",
        "Some of the following examples and code snippets were taken/adapted from:\n",
        "(a) NLTK webpage: https://www.nltk.org/\n",
        "(b) spaCy webpage: https://spacy.io\n",
        "(c) a notebook from Fernando Batista and Ricardo Ribeiro, my colleagues and dear friends from ISCTE. Thanks! (any mistake is on me)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Install (if needed)\n"
      ],
      "metadata": {
        "id": "hLAKGFc1ai71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U spacy # no need do execute in colab (maybe in your computer)"
      ],
      "metadata": {
        "id": "sdkF0zCvmvn1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e32063be-5869-4590-e13f-c4b85041dccc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.7)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.17.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.11.9)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.12/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.8.3)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.22.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.3.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Import"
      ],
      "metadata": {
        "id": "Y-uff6sMmZIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re     # regular expressions\n",
        "import nltk\n",
        "import spacy\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "t8_PkUDCmktq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Load"
      ],
      "metadata": {
        "id": "Km6VQzLfnTlu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NLTK\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "# spaCy\n",
        "nlp_en = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# For portuguese\n",
        "!python -m spacy download pt_core_news_sm\n",
        "nlp_pt = spacy.load(\"pt_core_news_sm\")\n"
      ],
      "metadata": {
        "id": "OFZeAgP2wIX9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "432a3ad8-bb58-44fb-8741-efd14dae5f8d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pt-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.8.0/pt_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pt-core-news-sm\n",
            "Successfully installed pt-core-news-sm-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Text to process\n"
      ],
      "metadata": {
        "id": "XS5CugRQIcrb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.1 Pre-processing"
      ],
      "metadata": {
        "id": "hl0L4AI4nhPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple text\n",
        "simple_text = \"Natural Language is my favourite course ever. I just love it.\"\n",
        "\n",
        "# External text (do not forget to upload it in colab -- check the left tab)\n",
        "file_path = '/content/sample_data/P7_dataset_testeNLP.txt'\n",
        "with open(file_path, 'r') as file:\n",
        "  external_text = file.read()\n",
        "\n",
        "# Split sentences considering a given list of punctuation marks\n",
        "def split_punctuation(text):\n",
        "  \"\"\"Splits specified punctuation from words in the given text.\"\"\"\n",
        "  # Pattern matches any word character (\\w) followed by any of the specified punctuation marks\n",
        "  # and ensures a space is inserted between the word and the punctuation mark.\n",
        "  punctuation_marks = [r'\\.', r'\\?', r'!', r',', r';']\n",
        "  for mark in punctuation_marks:\n",
        "    text = re.sub(f\"(\\\\w)({mark})\", r\"\\1 \\2\", text)\n",
        "  return text\n",
        "\n",
        "simple_text = split_punctuation(simple_text)\n",
        "print(simple_text)\n",
        "\n",
        "external_text = split_punctuation(external_text)\n",
        "print(external_text)"
      ],
      "metadata": {
        "id": "JR1XDYZbno_x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f25b6862-caea-4b40-c178-bf8ac1fa0d1a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natural Language is my favourite course ever . I just love it .\n",
            "O João come a sopa .\n",
            "A Maria é muito simpática , mas não gosta de sopa .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.2. Part-of-Speech tagging"
      ],
      "metadata": {
        "id": "PlLuRVpbIkkr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NLTK\n",
        "posNLTK = nltk.pos_tag(simple_text.split())\n",
        "print(\"NLTK_en:\", posNLTK)\n",
        "\n",
        "# spaCy\n",
        "spaCyText_en = nlp_en(simple_text)\n",
        "posSpaCy_en = [(token.text, token.tag_, token.pos_) for token in spaCyText_en]\n",
        "print(\"spaCy_en:\", posSpaCy_en)\n",
        "\n",
        "spaCyText_pt = nlp_pt(external_text)\n",
        "posSpaCy_pt = [(token.text, token.tag_, token.pos_) for token in spaCyText_pt]\n",
        "print(\"spaCy_pt:\", posSpaCy_pt)"
      ],
      "metadata": {
        "id": "HpDN7besHMUT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12368568-a15b-45ee-83f9-b521976ccaeb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK_en: [('Natural', 'JJ'), ('Language', 'NNP'), ('is', 'VBZ'), ('my', 'PRP$'), ('favourite', 'JJ'), ('course', 'NN'), ('ever', 'RB'), ('.', '.'), ('I', 'PRP'), ('just', 'RB'), ('love', 'VB'), ('it', 'PRP'), ('.', '.')]\n",
            "spaCy_en: [('Natural', 'NNP', 'PROPN'), ('Language', 'NNP', 'PROPN'), ('is', 'VBZ', 'AUX'), ('my', 'PRP$', 'PRON'), ('favourite', 'JJ', 'ADJ'), ('course', 'NN', 'NOUN'), ('ever', 'RB', 'ADV'), ('.', '.', 'PUNCT'), ('I', 'PRP', 'PRON'), ('just', 'RB', 'ADV'), ('love', 'VBP', 'VERB'), ('it', 'PRP', 'PRON'), ('.', '.', 'PUNCT')]\n",
            "spaCy_pt: [('O', 'DET', 'DET'), ('João', 'PROPN', 'PROPN'), ('come', 'VERB', 'VERB'), ('a', 'DET', 'DET'), ('sopa', 'NOUN', 'NOUN'), ('.', 'PUNCT', 'PUNCT'), ('\\n', 'SPACE', 'SPACE'), ('A', 'DET', 'DET'), ('Maria', 'PROPN', 'PROPN'), ('é', 'AUX', 'AUX'), ('muito', 'ADV', 'ADV'), ('simpática', 'ADJ', 'ADJ'), (',', 'PUNCT', 'PUNCT'), ('mas', 'CCONJ', 'CCONJ'), ('não', 'ADV', 'ADV'), ('gosta', 'VERB', 'VERB'), ('de', 'ADP', 'ADP'), ('sopa', 'NOUN', 'NOUN'), ('.', 'PUNCT', 'PUNCT')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.3 Find a specific PoS"
      ],
      "metadata": {
        "id": "xVr77xpu6Oeu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import count\n",
        "from spacy.parts_of_speech import PROPN\n",
        "\n",
        "def is_proper_noun(token):\n",
        "    return token.pos == spacy.parts_of_speech.PROPN\n",
        "\n",
        "# For PT\n",
        "count = 0\n",
        "for token in spaCyText_en:\n",
        "  if is_proper_noun(token):\n",
        "    print(token)\n",
        "    count += 1\n",
        "print(\"#proper nouns in english text = %d\" % count)\n",
        "\n",
        "# For PT\n",
        "count = 0\n",
        "for token in spaCyText_pt:\n",
        "  if is_proper_noun(token):\n",
        "    print(token)\n",
        "    count += 1\n",
        "print(\"#proper nouns in portuguese text = %d\" % count)"
      ],
      "metadata": {
        "id": "39v6IfD0gchD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f95e9882-bec7-453d-8c0b-e28ab6c68a17"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natural\n",
            "Language\n",
            "#proper nouns in english text = 2\n",
            "João\n",
            "Maria\n",
            "#proper nouns in portuguese text = 2\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}